{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.lines as mlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Datasets characteristics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "datasets = glob.glob(os.path.join(os.getcwd(),f'data/*'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "datasets_data = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    name = dataset.rsplit('/', 1)[-1]\n",
    "    df_path_train = os.path.join(dataset, 'split', 'train.csv')\n",
    "    df_path_test = os.path.join(dataset, 'split', 'test.csv')\n",
    "    df_train = pd.read_csv(df_path_train)\n",
    "    df_test = pd.read_csv(df_path_test)\n",
    "    df = pd.concat([df_train, df_test])\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['basket'] = df['basket'].apply(lambda x: x.strip('][').split(', '))\n",
    "    df['basket'] = df['basket'].apply(lambda x: [int(item) for item in x])\n",
    "    df['basket_size'] = df.apply(lambda row: len(row['basket']), axis=1)\n",
    "    avg_basket_size = df['basket_size'].mean()\n",
    "    num_baskets_per_user = df.groupby('user_id')['basket'].count().mean()\n",
    "    min_basket_size = df['basket_size'].min()\n",
    "    max_basket_size = df['basket_size'].max()\n",
    "    num_users = df['user_id'].nunique()\n",
    "    num_baskets = len(df)\n",
    "\n",
    "    exploded = df.explode('basket').rename({'basket': 'item_id'}, axis=1)\n",
    "    num_items = exploded['item_id'].nunique()\n",
    "\n",
    "    datasets_data = datasets_data._append({'Dataset': name, '#Users': num_users, '#Items': num_items, '#Baskets': num_baskets, 'Avg. basket size': avg_basket_size, '#Baskets per user': num_baskets_per_user, 'Min. basket size': min_basket_size, 'Max. basket size': max_basket_size}, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "datasets_data.to_csv(os.path.join(os.getcwd(),f'report_results/datasets_data.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Optimal hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "data = [\n",
    "    ['instacart', 900, 0.9, 0.7, 3, 0.9],\n",
    "    ['tafeng', 300, 0.9, 0.7, 7, 0.7],\n",
    "    ['dunnhumby', 900, 0.9, 0.6, 3, 0.2],\n",
    "    ['valuedshopper', 300, 1, 0.6, 7, 0.7],\n",
    "    ['tmall', 100, 0.6, 0.8, 18, 0.7],\n",
    "    ['taobao', 300, 0.6, 0.8, 10, 0.1]\n",
    "]\n",
    "\n",
    "columns = ['Dataset', 'Num Nearest Neighbors', 'Within decay rate', 'Group decay rate', 'Group count', 'Alpha']\n",
    "\n",
    "hyperparams = pd.DataFrame(data, columns=columns)\n",
    "hyperparams.to_csv(os.path.join(os.getcwd(),f'report_results/optimal_hyperparameters.csv'), index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fairness"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Specify the model for which you want to create results\n",
    "model = 'tifuknn' # 'top_personal', 'betavae'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Metrics vs. average basket size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "datasets = [dataset.split('/')[-1] for dataset in datasets]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "metrics = ['recall@010', 'recall@020', 'ndcg@010', 'ndcg@020', 'accuracy@010', 'accuracy@020',\n",
    " 'precision@010', 'precision@020', 'f1@010', 'f1@020', 'mrr@010', 'mrr@020', 'phr@010', 'phr@020']\n",
    "for metric in metrics:\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "    for dataset, ax in zip(datasets, axs.flat):\n",
    "        path = glob.glob(os.path.join(os.getcwd(), f'results/{model}_{dataset}_*_user_metrics.csv'))\n",
    "        df = pd.read_csv(path[0])\n",
    "        train_df = pd.read_csv(os.path.join(os.getcwd(), f'data/{dataset}/split/train.csv'))\n",
    "        train_df['basket_size'] = train_df.apply(lambda row: len(row['basket'].split(',')), axis=1)\n",
    "        basket_size = train_df.groupby('user_id')['basket_size'].mean().reset_index()\n",
    "        df = df.merge(basket_size, on=['user_id'])\n",
    "        if dataset == 'dunnhumby':\n",
    "            df['bin'] = pd.cut(df['basket_size'], list(range(0, 60, 5)))\n",
    "        else:\n",
    "            df['bin'] = pd.cut(df['basket_size'], list(range(0, min(5 * round(max(df['basket_size']) / 5), 100), 5)))\n",
    "\n",
    "        fairness = df.groupby('bin').agg({metric: 'mean', 'user_id': 'count'})\n",
    "        bar = fairness[metric].plot(kind='bar', color='y', label=f'avg. {metric}', ax=ax)\n",
    "        ax2 = ax.twinx()\n",
    "        line = fairness['user_id'].plot(kind='line', marker='d', secondary_y=True, label='#users', ax=ax2)\n",
    "        ax.set_title(dataset)  # Set subplot title\n",
    "\n",
    "        # Create proxy artists for the legend\n",
    "        proxy_bar = mpatches.Patch(color='y', label=f'avg. {metric}')\n",
    "        proxy_line = mlines.Line2D([], [], marker='d', label='#users')\n",
    "        lines = [proxy_bar, proxy_line]\n",
    "        labels = [line.get_label() for line in lines]\n",
    "        ax.legend(lines, labels, loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(os.getcwd(), f'report_results/fairness_basket_size/{model}_{metric}.png'))\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Metrics vs. % of popular items"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "metrics = ['recall@010', 'recall@020', 'ndcg@010', 'ndcg@020', 'accuracy@010', 'accuracy@020',\n",
    "           'precision@010', 'precision@020', 'f1@010', 'f1@020', 'mrr@010', 'mrr@020', 'phr@010', 'phr@020']\n",
    "\n",
    "for metric in metrics:\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        # Find ids of top x items\n",
    "        interactions = pd.read_csv(os.path.join(os.getcwd(), f'data/{dataset}/processed/interactions.csv'))\n",
    "        top_5 = int(0.20 * len(interactions['item_id']))\n",
    "        item_count = interactions['item_id'].value_counts().reset_index()\n",
    "        item_count['sum_cum'] = item_count['count'].cumsum()\n",
    "        top_5_ids = list(item_count[item_count['sum_cum'] <= top_5].item_id)\n",
    "\n",
    "        # Calculate percentage of popular items per user\n",
    "        train_df = pd.read_csv(os.path.join(os.getcwd(), f'data/{dataset}/split/train.csv'))\n",
    "        train_df['basket'] = train_df['basket'].apply(lambda x: x.strip('][').split(', '))\n",
    "        train_df['basket'] = train_df['basket'].apply(lambda x: [int(item) for item in x])\n",
    "        train_df['percent_of_popular_items'] = train_df['basket'].apply(\n",
    "            lambda x: len([item for item in x if item in top_5_ids]) / len(x))\n",
    "        popular_items = train_df.groupby('user_id')['percent_of_popular_items'].mean().reset_index()\n",
    "\n",
    "        # Merge with metrics\n",
    "        path = glob.glob(os.path.join(os.getcwd(), f'results/{model}_{dataset}_*_user_metrics.csv'))\n",
    "        df = pd.read_csv(path[0])\n",
    "        df = df.merge(popular_items, on=['user_id'])\n",
    "\n",
    "        # Plot the results\n",
    "        df['bin'] = pd.cut(df['percent_of_popular_items'], np.arange(0, 1.1, 0.1), include_lowest=True)\n",
    "        df['bin'] = df['bin'].astype(str)\n",
    "        df['bin'] = df['bin'].replace('(-0.001, 0.1]', '(0, 0.1]')\n",
    "\n",
    "        ax = axs[i // 3, i % 3]\n",
    "        fairness = df.groupby('bin').agg({metric: 'mean', 'user_id': 'count'})\n",
    "        fairness[metric].plot(kind='bar', color='y', label=f'avg. {metric}', ax=ax)\n",
    "        ax2 = ax.twinx()\n",
    "        fairness['user_id'].plot(kind='line', marker='d', secondary_y=True, label='#users', ax=ax2)\n",
    "        ax.set_xlabel('Percentage of Popular Items')\n",
    "        ax.set_ylabel(f'Average {metric}')\n",
    "        ax2.set_ylabel('#users')\n",
    "        ax.set_title(dataset)\n",
    "\n",
    "        # Create proxy artists for the legend\n",
    "        proxy_bar = mpatches.Patch(color='y', label=f'avg. {metric}')\n",
    "        proxy_line = mlines.Line2D([], [], marker='d', label='#users')\n",
    "        lines = [proxy_bar, proxy_line]\n",
    "        labels = [line.get_label() for line in lines]\n",
    "        ax.legend(lines, labels, loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(os.getcwd(), f'report_results/fairness_popular_items/{model}_{metric}.png'))\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Metrics vs. novelty"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Calculate percentage of popular items per user\n",
    "res = {}\n",
    "for dataset in datasets:\n",
    "    train_df = pd.read_csv(os.path.join(os.getcwd(), f'data/{dataset}/split/train.csv'))\n",
    "    train_df['basket'] = train_df['basket'].apply(lambda x: x.strip('][').split(', '))\n",
    "    train_df['basket'] = train_df['basket'].apply(lambda x: [int(item) for item in x])\n",
    "\n",
    "    test_df = pd.read_csv(os.path.join(os.getcwd(), f'data/{dataset}/split/test.csv'))\n",
    "    test_df['basket'] = test_df['basket'].apply(lambda x: x.strip('][').split(', '))\n",
    "    test_df['basket'] = test_df['basket'].apply(lambda x: [int(item) for item in x])\n",
    "\n",
    "    past_items = train_df.groupby('user_id')['basket'].sum().reset_index()\n",
    "    past_items['past_items'] = past_items['basket'].apply(lambda x: list(set(x)))\n",
    "    past_items = past_items.drop(columns = ['basket'])\n",
    "    test_df = test_df.merge(past_items, on=['user_id'])\n",
    "    test_df['novelty'] = test_df.apply(lambda row: len([item for item in row['basket'] if item not in row['past_items']]) / len(row['basket']), axis=1)\n",
    "    novelty = test_df[['user_id', 'novelty']]\n",
    "\n",
    "    path = glob.glob(os.path.join(os.getcwd(), f'results/{model}_{dataset}_*_user_metrics.csv'))\n",
    "    df = pd.read_csv(path[0])\n",
    "    df = df.merge(novelty, on=['user_id'])\n",
    "\n",
    "    df['bin'] = pd.cut(df['novelty'], np.arange(0, 1.1, 0.1), include_lowest=True)\n",
    "    df['bin'] = df['bin'].astype(str)\n",
    "    df['bin'] = df['bin'].replace('(-0.001, 0.1]', '(0, 0.1]')\n",
    "\n",
    "    res[dataset] = df\n",
    "\n",
    "for metric in metrics:\n",
    "    fig, axs = plt.subplots(2, 3, figsize=(12, 8))\n",
    "    for i, (dataset, df) in enumerate(res.items()):\n",
    "        ax = axs[i // 3, i % 3]\n",
    "        fairness = df.groupby('bin').agg({metric: 'mean', 'user_id': 'count'})\n",
    "        fairness[metric].plot(kind='bar', color='y', label=f'avg. {metric}', ax=ax)\n",
    "        ax2 = ax.twinx()\n",
    "        fairness['user_id'].plot(kind='line', marker='d', secondary_y=True, label='#users', ax=ax2)\n",
    "        ax.set_xlabel('Percentage of unseen items')\n",
    "        ax.set_ylabel(f'Average {metric}')\n",
    "        ax2.set_ylabel('#users')\n",
    "        ax.set_title(dataset)\n",
    "\n",
    "        # Create proxy artists for the legend\n",
    "        proxy_bar = mpatches.Patch(color='y', label=f'avg. {metric}')\n",
    "        proxy_line = mlines.Line2D([], [], marker='d', label='#users')\n",
    "        lines = [proxy_bar, proxy_line]\n",
    "        labels = [line.get_label() for line in lines]\n",
    "        ax.legend(lines, labels, loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(os.getcwd(), f'report_results/fairness_novelty/{model}_{metric}.png'))\n",
    "    plt.close()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
